{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rudolf\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Rudolf\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Rudolf\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "In C:\\Users\\Rudolf\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Rudolf\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Rudolf\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\Rudolf\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Rudolf\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Rudolf\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Rudolf\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\Rudolf\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and get principal information about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/2el1730-machine-learning/train_ml.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b5a51af1b41d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/2el1730-machine-learning/train_ml.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/2el1730-machine-learning/test_ml.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1043\u001b[0m             )\n\u001b[0;32m   1044\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1361\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m         )\n\u001b[0;32m   1365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    642\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m             )\n\u001b[0;32m    646\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/2el1730-machine-learning/train_ml.csv'"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_ml.csv', index_col=0)\n",
    "test_df = pd.read_csv('test_ml.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring links between features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.groupby(['tld','org'])[['updates','personal','promotions','forums','purchases','travel','spam','social']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring features alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into real features and predictions\n",
    "def split_X_y(Xa):\n",
    "    return Xa.drop(['updates','personal','promotions','forums','purchases','travel',\n",
    "                    'spam','social'],axis=1), Xa[['updates','personal','promotions',\n",
    "                                                  'forums','purchases','travel','spam','social']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_X_y(train_df.copy())\n",
    "print(\"Shape of design matrix of training set:\", X.shape)\n",
    "print(\"Shape of labels matrix of training set:\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(X.columns)\n",
    "categorical_features = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "numerical_features = X.select_dtypes(exclude=['object','category']).columns.tolist()\n",
    "\n",
    "print('Columns:')\n",
    "print(columns)\n",
    "print()\n",
    "print('Categorical features:')\n",
    "print(categorical_features)\n",
    "print()\n",
    "print('Numerical features:')\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display number of missing values for each column\n",
    "for col in columns:\n",
    "    print(col,'----------------',X[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display value counts for each categorical feature\n",
    "for col in categorical_features:\n",
    "    print(\"Column\", col)\n",
    "    print(X[col].value_counts())\n",
    "    print('*****************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing, feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve day, month, time, year, number of day from the feature \"date\"\n",
    "days=['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
    "months=['Jan','Feb','Mar','Apr','May','Jun','Jul','Sep','Oct','Nov','Dec']\n",
    "\n",
    "def day_parse(L):\n",
    "    for day in days:\n",
    "        if day in L:\n",
    "            return day\n",
    "\n",
    "def month_parse(L):\n",
    "    for month in months:\n",
    "        if month in L:\n",
    "            return month\n",
    "\n",
    "def time_parse(L):\n",
    "    M=\"\".join(L.split(\" \"))\n",
    "    plus=0;minus=0\n",
    "    for i in range(len(M)):\n",
    "        if M[i]==':':\n",
    "            a=i\n",
    "        if M[i]=='+' and (M[i-1] in ['0','1','2','3','4','5','6','7','8','9']) and (M[i+1] in ['0','1','2','3','4','5','6','7','8','9']):\n",
    "            plus=i\n",
    "        if M[i]=='-' and (M[i-1] in ['0','1','2','3','4','5','6','7','8','9']) and (M[i+1] in ['0','1','2','3','4','5','6','7','8','9']):\n",
    "            minus=i\n",
    "            \n",
    "    time1=int(M[a-2:a]+M[a+1:a+3])\n",
    "    \n",
    "    \n",
    "    if plus!=0:\n",
    "        time2=int(M[plus+1:plus+5])\n",
    "        time=(time1+time2)%2400\n",
    "    elif minus!=0:\n",
    "        time2=int(M[minus+1:minus+5])\n",
    "        time=(time1-time2)%2400\n",
    "    elif plus==0 and minus==0:\n",
    "        time=time1\n",
    "        \n",
    "    return time\n",
    "\n",
    "def year_parse(L):\n",
    "    M=\" \".join(L.split(\" \"))\n",
    "    try :\n",
    "        return int(re.findall('[0-9][0-9][0-9][0-9]',M)[0])\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def number_date_parse(L):\n",
    "    M=\" \".join(L.split(\" \"))\n",
    "    try :\n",
    "        return int(re.findall('[0-9][0-9]',M)[0])\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_process(data1):\n",
    "    data=data1.copy()\n",
    "    data['day']=data['date'].apply(day_parse)\n",
    "    data['month']=data['date'].apply(month_parse)\n",
    "    data['time']=data['date'].apply(time_parse)\n",
    "    data['year']=data['date'].apply(year_parse)\n",
    "    data['number_date']=data['date'].apply(number_date_parse)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = date_process(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummies creation for months and days\n",
    "def create_dummies(data):\n",
    "    return pd.get_dummies(data, columns=['month','day'], prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = create_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_url_size=1\n",
    "def ratio_features(data):\n",
    "    data['urls_ratio']=data['urls']*average_url_size/data['chars_in_body']\n",
    "    data['images_ratio']=data['images']/data['chars_in_body']\n",
    "    data['chars_in_subject_ratio']=data['chars_in_subject']/data['chars_in_body']\n",
    "    data['salu_design_']=data['salutations']*data['designation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.columns)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put all the strings in lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the strings in lower case\n",
    "def lower_case(data):\n",
    "    for col in data.select_dtypes(include=['object','category']).columns.tolist():\n",
    "        data[col]=data[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_case(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mail types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting mail_type columns (e.g. \"multipart/alternative\" -> \"multipart\" + \"alternative\")\n",
    "mail_type = train_df['mail_type'].unique().tolist()\n",
    "\n",
    "M = []\n",
    "for l in mail_type:\n",
    "    a = \"\".join(str(l).split(\" \")).lower()\n",
    "    M += (a.split('/'))\n",
    "keys = set(M)\n",
    "\n",
    "def mail_type_transform(data):\n",
    "    m=data.shape[0]\n",
    "    newColumns={}\n",
    "    for key in keys:\n",
    "        temp=[]\n",
    "        for i in range(m):\n",
    "            if key in list( \"\".join(str(data['mail_type'].iloc[i]).split(\" \")).split('/')):\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        newColumns[key]=temp\n",
    "    for key in newColumns.keys():\n",
    "        data[key]=newColumns[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mail_type_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropping(data, cols=['date','mail_type','org','tld','nan']):\n",
    "    data.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropping(X,['date','mail_type','nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X.columns)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = X.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(new_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove low variance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Define thresholds to check\n",
    "thresholds = np.arange(0.0, 1, 0.010)\n",
    "# Apply transform with each threshold\n",
    "results = list()\n",
    "\n",
    "for t in thresholds:\n",
    "    # Define the transform\n",
    "    transform = VarianceThreshold(threshold=t)\n",
    "    # Transform the input data\n",
    "    X_sel = transform.fit_transform(X.select_dtypes(exclude=['object','category']))\n",
    "    # Determine the number of input features\n",
    "    n_features = X_sel.shape[1]\n",
    "    print('>Threshold=%.2f, Features=%d' % (t, n_features))\n",
    "    # Store the result\n",
    "    results.append(n_features)\n",
    "# Plot the threshold vs the number of selected features\n",
    "plt.plot(thresholds, results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datavar = X.copy()\n",
    "\n",
    "def variance_selector(data, threshold = 0.05):\n",
    "    if threshold == 0:\n",
    "        return data\n",
    "    else:\n",
    "        selector = VarianceThreshold(threshold)\n",
    "        col1 = datavar.select_dtypes(exclude=['number']).columns.tolist()\n",
    "        selector.fit(datavar[datavar.select_dtypes(include=['number']).columns]) \n",
    "        return data[list(set(col1+datavar.columns[selector.get_support(indices=True)].tolist()))] \n",
    "\n",
    "X_sel = variance_selector(X, threshold = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "sorted(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_sel.shape)\n",
    "sorted(X_sel.columns.tolist())\n",
    "# 8 features removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing function (does all the previous steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = date_process(data)\n",
    "    data = create_dummies(data)\n",
    "    ratio_features(data)\n",
    "    lower_case(data)\n",
    "    mail_type_transform(data)\n",
    "    dropping(data,['date','mail_type','nan'])\n",
    "    data = variance_selector(data, threshold = 0.01)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(inner_model):\n",
    "    # Obtaining the selected features\n",
    "    categorical_features = X_sel.select_dtypes(include=['object','category']).columns.tolist()\n",
    "    numerical_features = X_sel.select_dtypes(exclude=['object','category']).columns.tolist()\n",
    "    \n",
    "    # Pipeline with imputation, standardisation, one hot enconding, model creation\n",
    "    numerical_pipeline = Pipeline(steps=[('imputation',SimpleImputer(strategy='median')),\n",
    "                                         ('standard',RobustScaler())])\n",
    "\n",
    "    categorical_pipeline = Pipeline(steps=[('imputation',SimpleImputer(strategy='most_frequent')),\n",
    "                                          ('oneHotencode',OneHotEncoder(handle_unknown='ignore'))\n",
    "                                          ])\n",
    "\n",
    "    preparation = ColumnTransformer(transformers=[('categorical',categorical_pipeline, \n",
    "                                                   categorical_features),\n",
    "                                                  ('numerical',numerical_pipeline,\n",
    "                                                   numerical_features)])\n",
    "    \n",
    "    model = Pipeline(steps=[('preparation', preparation),\n",
    "                            ('model', OneVsRestClassifier(inner_model))])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of the type of model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of model to be tested\n",
    "inner_models = [XGBClassifier(max_depth= 9, min_child_weight= 1 , gamma= 0.4, colsample_bytree= 0.7, subsample= 1, \n",
    "                            reg_alpha= 0.0001, learning_rate= 0.2, n_estimators= 350)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting in train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sel, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"models_estimation.txt\",\"a\")\n",
    "variance_threshold = 0.01\n",
    "\n",
    "for inner_model in inner_models:\n",
    "    model = model_pipeline(inner_model)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(\"Date: \",datetime.now())\n",
    "    print(\"Variance threshold: \",variance_threshold)\n",
    "    print(\"Model name: \", type(inner_model).__name__)\n",
    "    print(\"Model parameters: \", inner_model.get_params())\n",
    "    # Printing model score\n",
    "    model_train_score=model.score(X_train, y_train)\n",
    "    model_test_score=model.score(X_test, y_test)\n",
    "    model_train_logLoss=log_loss(y_train,model.predict_proba(X_train))\n",
    "    model_test_logLoss=log_loss(y_test,model.predict_proba(X_test))\n",
    "    print(\"Model score on the train set : %.2f\" % model_train_score)\n",
    "    print(\"Model score on the test set : %.2f\" % model_test_score)\n",
    "\n",
    "    #Printing model log score \n",
    "    print(\"Model log loss on the train set: \", model_train_logLoss)\n",
    "    print(\"Model log loss on the test set: \",model_test_logLoss )\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    \n",
    "    file.write(\"--------------------------------------------------------------------------\\r\\n\")\n",
    "    file.write(\"Date: {}\\r\\n\".format(datetime.now()))\n",
    "    file.write(\"Variance threshold: {}\\r\\n\".format(variance_threshold) )\n",
    "    file.write(\"Model name: {}\\r\\n\".format(type(inner_model).__name__))\n",
    "    file.write(\"Model parameters: {}\\r\\n\".format( inner_model.get_params()))\n",
    "    file.write(\"Model score on the train set : {}\\r\\n\".format(model.score(X_train, y_train)))\n",
    "    file.write(\"Model score on the test set : {}\\r\\n\".format(model.score(X_test, y_test)))\n",
    "    file.write(\"Model log loss on the train set: {}\\r\\n\".format(log_loss(y_train,model.predict_proba(X_train))))\n",
    "    file.write(\"Model log loss on the test set: {}\\r\\n\".format(log_loss(y_test,model.predict_proba(X_test))))\n",
    "    file.write(\"--------------------------------------------------------------------------\\r\\n\")\n",
    "file.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters tuning (Grid Search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model_pipeline(DecisionTreeClassifier())\n",
    "params_dt={'model__estimator__min_samples_leaf': range(1,10),\n",
    "            'model__estimator__max_depth': (20,25,50,100,200,300),\n",
    "            'model__estimator__criterion': ('gini', 'entropy'),\n",
    "            'model__estimator__max_features': ('auto', 'sqrt', 'log2'),\n",
    "            'model__estimator__min_samples_split': (2,3,4,5,6)}\n",
    "\n",
    "gsearch_20 = GridSearchCV(estimator=model,param_grid=params_dt,\n",
    "                          scoring='neg_log_loss',n_jobs=4,cv=5)\n",
    "gsearch_20.fit(X_train,y_train)\n",
    "model = gsearch_20.best_estimator_\n",
    "print(gsearch_20.best_params_)\n",
    "\n",
    "# Printing model score\n",
    "model_train_score=model.score(X_train, y_train)\n",
    "model_test_score=model.score(X_test, y_test)\n",
    "model_train_logLoss=log_loss(y_train,model.predict_proba(X_train))\n",
    "model_test_logLoss=log_loss(y_test,model.predict_proba(X_test))\n",
    "print(\"Model score on the train set : %.2f\" % model_train_score)\n",
    "print(\"Model score on the test set : %.2f\" % model_test_score)\n",
    "\n",
    "#Printing model log score \n",
    "print(\"Model log loss on the train set: \", model_train_logLoss)\n",
    "print(\"Model log loss on the test set: \",model_test_logLoss )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with plain RandomForestClassifier, and update it after each gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_pipeline(RandomForestClassifier())\n",
    "\n",
    "params_rf_11={'model__estimator__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'model__estimator__max_features': ['auto', 'sqrt'],\n",
    " 'model__estimator__min_samples_leaf': [1, 2, 4],\n",
    " 'model__estimator__min_samples_split': [2, 5, 10],\n",
    " 'model__estimator__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "\n",
    "gsearch11 = RandomizedSearchCV(estimator=model, param_distributions=params_rf_11,\n",
    "                             scoring='neg_log_loss',n_jobs=4,cv=5)\n",
    "gsearch11.fit(X_train,y_train)\n",
    "model = gsearch11.best_estimator_\n",
    "print(gsearch11.best_params_)\n",
    "\n",
    "# Printing model score\n",
    "model_train_score=model.score(X_train, y_train)\n",
    "model_test_score=model.score(X_test, y_test)\n",
    "model_train_logLoss=log_loss(y_train,model.predict_proba(X_train))\n",
    "model_test_logLoss=log_loss(y_test,model.predict_proba(X_test))\n",
    "print(\"Model score on the train set : %.2f\" % model_train_score)\n",
    "print(\"Model score on the test set : %.2f\" % model_test_score)\n",
    "\n",
    "#Printing model log score \n",
    "print(\"Model log loss on the train set: \", model_train_logLoss)\n",
    "print(\"Model log loss on the test set: \",model_test_logLoss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_pipeline(RandomForestClassifier(min_samples_leaf=1))\n",
    "\n",
    "params_rf_12={'model__estimator__max_depth': [90, 100, 200,500,1000,None],\n",
    " 'model__estimator__max_features': ['auto', 'sqrt'],\n",
    " 'model__estimator__min_samples_split': [9, 10,11],\n",
    " 'model__estimator__n_estimators': [700,750, 800, 850,900]}\n",
    "\n",
    "gsearch12 = RandomizedSearchCV(estimator=model,param_distributions=params_rf_12,\n",
    "                               scoring='neg_log_loss',n_jobs=4,cv=5)\n",
    "gsearch12.fit(X_train,y_train)\n",
    "model = gsearch_12.best_estimator_\n",
    "print(gsearch_12.best_params_)\n",
    "\n",
    "# Printing model score\n",
    "model_train_score=model.score(X_train, y_train)\n",
    "model_test_score=model.score(X_test, y_test)\n",
    "model_train_logLoss=log_loss(y_train,model.predict_proba(X_train))\n",
    "model_test_logLoss=log_loss(y_test,model.predict_proba(X_test))\n",
    "print(\"Model score on the train set : %.2f\" % model_train_score)\n",
    "print(\"Model score on the test set : %.2f\" % model_test_score)\n",
    "\n",
    "#Printing model log score \n",
    "print(\"Model log loss on the train set: \", model_train_logLoss)\n",
    "print(\"Model log loss on the test set: \",model_test_logLoss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_pipeline(RandomForestClassifier(min_samples_leaf=1,min_samples_split=9))\n",
    "\n",
    "params_rf_13={'model__estimator__max_depth': [100,125,150],\n",
    " 'model__estimator__max_features': ['auto', 'sqrt'],\n",
    " 'model__estimator__n_estimators': [900,950,1000]}\n",
    "\n",
    "gsearch13 = RandomizedSearchCV(estimator=model,param_distributions=params_rf_13, \n",
    "                               scoring='neg_log_loss',n_jobs=4,cv=5)\n",
    "gsearch13.fit(X_train,y_train)\n",
    "model = gsearch13.best_estimator_\n",
    "print(gsearch13.best_params_)\n",
    "\n",
    "# Printing model score\n",
    "model_train_score=model.score(X_train, y_train)\n",
    "model_test_score=model.score(X_test, y_test)\n",
    "model_train_logLoss=log_loss(y_train,model.predict_proba(X_train))\n",
    "model_test_logLoss=log_loss(y_test,model.predict_proba(X_test))\n",
    "print(\"Model score on the train set : %.2f\" % model_train_score)\n",
    "print(\"Model score on the test set : %.2f\" % model_test_score)\n",
    "\n",
    "#Printing model log score \n",
    "print(\"Model log loss on the train set: \", model_train_logLoss)\n",
    "print(\"Model log loss on the test set: \",model_test_logLoss )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with plain XGBClassifier, and update it after each gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_pipeline(XGBClassifier())\n",
    "param_test1 = {'model__estimator__max_depth': range(3,10,2),\n",
    "               'model__estimator__min_child_weight': range(1,6,2)}\n",
    "gsearch1 = GridSearchCV(estimator=model,param_grid=param_test1, \n",
    "                        scoring='neg_log_loss',n_jobs=4,cv=5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "model = gsearch1.best_estimator_\n",
    "gsearch1.best_params_, gsearch1.best_score_\n",
    "\n",
    "# max_depth = 9, min_child_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {'model__estimator__gamma': [i/10.0 for i in range(0,5)]}\n",
    "gsearch2 = GridSearchCV(estimator=model,param_grid=param_test2, \n",
    "                        scoring='neg_log_loss',n_jobs=4,cv=5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "model = gsearch2.best_estimator_\n",
    "gsearch2.best_params_, gsearch2.best_score_\n",
    "\n",
    "# gamma = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {'model__estimator__subsample': [i/10.0 for i in range(6,11)],\n",
    "               'model__estimator__colsample_bytree': [i/10.0 for i in range(6,11)]}\n",
    "gsearch3 = GridSearchCV(estimator=model,param_grid=param_test3,\n",
    "                        scoring='neg_log_loss',n_jobs=4,cv=5)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "model = gsearch3.best_estimator_\n",
    "gsearch3.best_params_, gsearch3.best_score_\n",
    "\n",
    "# subsample = 1, colsamble_bytree = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {'model__estimator__reg_alpha': [1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 100]}\n",
    "gsearch4 = GridSearchCV(estimator=model,param_grid=param_test4,\n",
    "                        scoring='neg_log_loss',n_jobs=4,cv=5)\n",
    "gsearch4.fit(X_train,y_train)\n",
    "model = gsearch4.best_estimator_\n",
    "gsearch4.best_params_, gsearch4.best_score_\n",
    "\n",
    "# reg_alpha = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {'model__estimator__learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "               'model__estimator__n_estimators': [250, 300, 350, 400]}\n",
    "gsearch5 = GridSearchCV(estimator=model,param_grid=param_test5, \n",
    "                        scoring='neg_log_loss',n_jobs=4,cv=5)\n",
    "gsearch5.fit(X_train,y_train)\n",
    "model = gsearch5.best_estimator_\n",
    "gsearch5.best_params_, gsearch5.best_score_\n",
    "\n",
    "# learning_rate = 0.2, n_estimators = 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:57:28] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:57:45] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "model = model_pipeline(XGBClassifier(max_depth = 9, min_child_weight = 1, gamma = 0.4,\n",
    "                                     colsample_bytree = 0.7, subsample = 1,\n",
    "                                     reg_alpha = 0.0001, learning_rate = 0.2, \n",
    "                                     n_estimators = 350))\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du modèle sur training set: 0.82\n",
      "Score du modèle sur test set: 0.79\n",
      "\n",
      "Log-loss du modèle sur training set: 2.11\n",
      "Log-loss du modèle sur test set: 2.12\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy du modèle sur training set: %.2f\" % model.score(X_train, y_train))\n",
    "print(\"Score du modèle sur test set: %.2f\" % model.score(X_test, y_test))\n",
    "\n",
    "print()\n",
    "\n",
    "log_loss_train = log_loss(y_train, model.predict_proba(X_train))\n",
    "print(\"Log-loss du modèle sur training set: %.2f\" % log_loss_train)\n",
    "log_loss_test = log_loss(y_test, model.predict_proba(X_test))\n",
    "print(\"Log-loss du modèle sur test set: %.2f\" % log_loss_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final training, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the entire training set and show performance\n",
    "X, y = split_X_y(pd.read_csv('../input/2el1730-machine-learning/train_ml.csv', index_col=0).copy())\n",
    "X_preprocessed = preprocess(X)\n",
    "model.fit(X_preprocessed, y)\n",
    "\n",
    "accuracy_all_train = model.score(X_preprocessed, y)\n",
    "print(\"Accuracy du modèle sur training set entier: %.2f\" % accuracy_all_train)\n",
    "\n",
    "log_loss_all_train = log_loss(y, model.predict_proba(X_preprocessed))\n",
    "print(\"Log-loss du modèle sur training set entier: %.2f\" % log_loss_all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the unlabled data and save results to submission file\n",
    "test_df = pd.read_csv('../input/2el1730-machine-learning/test_ml.csv', index_col=0)\n",
    "test_df_preprocessed = preprocess(test_df)\n",
    "pred_y = model.predict_proba(test_df_preprocessed)\n",
    "\n",
    "pred_df = pd.DataFrame(pred_y, columns=['updates', 'personal', 'promotions',\n",
    "                        'forums', 'purchases', 'travel',\n",
    "                        'spam', 'social'])\n",
    "pred_df.to_csv(\"submission_{}_var_{}_.csv\".format(\"Bagg_XGBClassifier_cv\",variance_threshold)\n",
    "               , index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsuccesful implementation of a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "X_train.shape,y_train.shape\n",
    "input = X_train.shape[1]\n",
    "X_train = X_train.drop(['org','tld'], axis=1)\n",
    "X_test = X_test.drop(['org','tld'], axis=1)\n",
    "\n",
    "# determine the supported device\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "# convert a df to tensor to be used in pytorch\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)\n",
    "\n",
    "X_train = df_to_tensor(X_train)\n",
    "X_test = df_to_tensor(X_test)\n",
    "y_train = df_to_tensor(y_train)\n",
    "y_test = df_to_tensor(y_test)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(43, 200)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.fc3 = nn.Linear(100, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "torch.reshape(X_train, (X_train.shape[0],X_train.shape[1]))\n",
    "torch.reshape(X_test, (X_test.shape[0],X_test.shape[1]))\n",
    "torch.reshape(y_train, (y_train.shape[0],y_train.shape[1]))\n",
    "torch.reshape(y_test, (y_test.shape[0],y_test.shape[1]))\n",
    "\n",
    "#Normalisation de nan par 0\n",
    "test = torch.isnan(X_train)\n",
    "for i in range (X_train.shape[0]):\n",
    "    for j in range(X_train.shape[1]):\n",
    "        if test[i,j]:\n",
    "            X_train[i,j] =0\n",
    "\n",
    "#Normalisation de nan par 0\n",
    "test = torch.isnan(X_test)\n",
    "for i in range (X_test.shape[0]):\n",
    "    for j in range(X_test.shape[1]):\n",
    "        if test[i,j]:\n",
    "            X_test[i,j] =0\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(X_train[i,:])\n",
    "        loss = criterion(outputs, y_train[i,:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%1000==0:\n",
    "            print(loss)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "output = loss(m(input), target)\n",
    "print(output)\n",
    "\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "outputs = net(X_test)\n",
    "\n",
    "# Printing model score\n",
    "print(\"Score du modèle : %.2f\" % criterion(net(X_train), y_train))\n",
    "print(\"Score du modèle : %.2f\" % criterion(net(X_test), y_test))\n",
    "\n",
    "print(net(X_test[1,:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
